{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your MongoDB connection details\n",
    "import pymongo\n",
    "import requests\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import os\n",
    "import pickle\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import requests\n",
    "import re\n",
    "from deepface import DeepFace\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONNECT_&_GET_FILES_FROM_DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_db(database_name=\"officialDB\",collection_name=\"officialDB\"):\n",
    "    client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "    db = client[database_name]\n",
    "    collection = db[collection_name]\n",
    "    return collection\n",
    "\n",
    "\n",
    "def get_shareable_link_from_google_drive(url):\n",
    "    file_id_match = re.search(r'[-\\w]{25,}', url)\n",
    "    direct_link=\"\"\n",
    "    if file_id_match:\n",
    "        file_id = file_id_match.group(0)\n",
    "        # Construct the direct download link\n",
    "        direct_link = f\"https://drive.google.com/uc?export=view&id={file_id}\"\n",
    "    return direct_link\n",
    "\n",
    "def get_fields_items(collection):\n",
    "    name_list = []\n",
    "    link_list = []\n",
    "    cursor = collection.find()  # Get all documents in the collection\n",
    "    for document in cursor:\n",
    "        name_list.append(document[\"ID\"])\n",
    "        new_link = get_shareable_link_from_google_drive(document[\"URL\"])\n",
    "        link_list.append(new_link)\n",
    "    return name_list, link_list\n",
    "collection=connect_to_db()\n",
    "name_list,link_list = get_fields_items(collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET_IMAGE_&_CREATE_EMBEDDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_image(image_url,model_type=\"face_recognition\"):\n",
    "    response = requests.get(image_url)\n",
    "    if response.status_code==200:\n",
    "\n",
    "    # response.raise_for_status()  # Raise an error if download fails\n",
    "\n",
    "    # Load the image using PIL for error handling\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        # cv2.imshow(\"image\", np.array(img))\n",
    "        image = cv2.cvtColor(np.array(img), cv2.COLOR_BGR2RGB)\n",
    "        if model_type == \"face_recognition\":\n",
    "            face_locations = face_recognition.face_locations(image, number_of_times_to_upsample=2, model=\"hog\")\n",
    "            if len(face_locations) == 0:\n",
    "                print(f\"No faces detected in image: {image_url}\")\n",
    "                return None\n",
    "\n",
    "            face_encoding = face_recognition.face_encodings(image, face_locations)[0]  # Handle single face only\n",
    "            return face_encoding\n",
    "        if model_type==\"facenet\":\n",
    "            mtcnn = MTCNN(image_size=160, margin=0, min_face_size=20)\n",
    "            resnet = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "            img_cropped = mtcnn(image)\n",
    "            if img_cropped is not None:\n",
    "                img_embedding = resnet(img_cropped.unsqueeze(0))\n",
    "                # print(len(img_embedding))\n",
    "                # print(len(img_embedding))\n",
    "                img_embedding = img_embedding.detach().numpy()\n",
    "                # print(type(img_embedding))\n",
    "                return img_embedding\n",
    "            else:\n",
    "                print(f\"No faces detected in image: {image_url}\")\n",
    "        if model_type==\"deepface\":\n",
    "                try:\n",
    "                    embedding=DeepFace.represent(image)\n",
    "                    print(type(embedding))\n",
    "                    if len(embedding):\n",
    "                        return embedding\n",
    "                except:\n",
    "                    print(f\"No faces detected in image: {image_url}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "def get_embedding_and_name_list(name_list,link_list,model_type=\"face_recognition\"):\n",
    "\n",
    "\n",
    "    known_face_encodings = []\n",
    "    known_face_names = []\n",
    "    for   name, link  in zip(name_list, link_list):\n",
    "        face_encoding = get_image(link,model_type)\n",
    "        if face_encoding is not None:\n",
    "            known_face_encodings.append(face_encoding)\n",
    "            known_face_names.append(name)\n",
    "    return known_face_encodings , known_face_names\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FACE-RECOGNITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No faces detected in image: https://drive.google.com/uc?export=view&id=1GK-rdA0MZVs_jx1YkWUdFuRFjG24Cp3I\n",
      "No faces detected in image: https://drive.google.com/uc?export=view&id=1c2dfJ51Ytlemp6eF-ogjiIKTL1hrnvqa\n",
      "No faces detected in image: https://drive.google.com/uc?export=view&id=1C6WgNu8zH85rqTzCMRFyhbCb4QuSE3bK\n",
      "No faces detected in image: https://drive.google.com/uc?export=view&id=1duYnUTrj4uAmutYsAF_5wWIk1fxIKaj0\n",
      "21\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_type=\"face_recognition\"\n",
    "known_face_encodings , known_face_names=get_embedding_and_name_list(name_list,link_list,model_type)\n",
    "\n",
    "# # print(known_face_encodings)\n",
    "# # print(known_face_names)\n",
    "with open(f'{model_type}_known_faces.pickle', 'wb') as f:\n",
    "    pickle.dump((known_face_encodings, known_face_names), f)\n",
    "\n",
    "print(len(known_face_encodings))\n",
    "print(len(known_face_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FACE-NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "25\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_type=\"facenet\"\n",
    "known_face_names = []\n",
    "known_face_encodings = []\n",
    "\n",
    "known_face_encodings , known_face_names=get_embedding_and_name_list(name_list,link_list,model_type)\n",
    "\n",
    "# # print(known_face_encodings)\n",
    "# # print(known_face_names)\n",
    "with open(f'{model_type}_known_faces.pickle', 'wb') as f:\n",
    "    pickle.dump((known_face_encodings, known_face_names), f)\n",
    "\n",
    "print(len(known_face_encodings))\n",
    "print(len(known_face_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEEP-FACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "No faces detected in image: https://drive.google.com/uc?export=view&id=1PvpNIF1HuxZu3Aw7m7x8UcmznnF2NzlX\n",
      "No faces detected in image: https://drive.google.com/uc?export=view&id=1hwzTDouxCvQV9_vuvUJpDFie2KPINRt8\n",
      "No faces detected in image: https://drive.google.com/uc?export=view&id=1GK-rdA0MZVs_jx1YkWUdFuRFjG24Cp3I\n",
      "<class 'list'>\n",
      "No faces detected in image: https://drive.google.com/uc?export=view&id=1lE6Zl750VkykzvTJQ_KxkVobC0RurrgN\n",
      "<class 'list'>\n",
      "No faces detected in image: https://drive.google.com/uc?export=view&id=1c2dfJ51Ytlemp6eF-ogjiIKTL1hrnvqa\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "No faces detected in image: https://drive.google.com/uc?export=view&id=1C6WgNu8zH85rqTzCMRFyhbCb4QuSE3bK\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "No faces detected in image: https://drive.google.com/uc?export=view&id=1duYnUTrj4uAmutYsAF_5wWIk1fxIKaj0\n",
      "<class 'list'>\n",
      "No faces detected in image: https://drive.google.com/uc?export=view&id=1OfHSLxOR1J1cbVCy-37sThFAY1uPz7r6\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "18\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "model_type=\"deepface\"\n",
    "known_face_names = []\n",
    "known_face_encodings = []\n",
    "\n",
    "known_face_encodings , known_face_names=get_embedding_and_name_list(name_list,link_list,model_type)\n",
    "\n",
    "# # print(known_face_encodings)\n",
    "# # print(known_face_names)\n",
    "with open(f'{model_type}_known_faces.pickle', 'wb') as f:\n",
    "    pickle.dump((known_face_encodings, known_face_names), f)\n",
    "\n",
    "print(len(known_face_encodings))\n",
    "print(len(known_face_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UPDATE EMBEDDING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No faces detected in image: https://drive.google.com/uc?export=view&id=1GK-rdA0MZVs_jx1YkWUdFuRFjG24Cp3I\n",
      "No faces detected in image: https://drive.google.com/uc?export=view&id=1c2dfJ51Ytlemp6eF-ogjiIKTL1hrnvqa\n",
      "No faces detected in image: https://drive.google.com/uc?export=view&id=1C6WgNu8zH85rqTzCMRFyhbCb4QuSE3bK\n",
      "No faces detected in image: https://drive.google.com/uc?export=view&id=1duYnUTrj4uAmutYsAF_5wWIk1fxIKaj0\n"
     ]
    }
   ],
   "source": [
    "def get_updated_embedding_and_name_list(name_list, link_list, id_list, model_type):\n",
    "    known_face_encodings = []\n",
    "    known_face_names = []\n",
    "\n",
    "    with open(f'{model_type}_known_faces.pickle', 'rb') as f:\n",
    "        known_face_encodings, known_face_names = pickle.load(f)\n",
    "\n",
    "    for name, link in zip(name_list, link_list):\n",
    "        if name in known_face_names:\n",
    "            continue\n",
    "\n",
    "        face_encoding = get_image(link)\n",
    "        if face_encoding is not None:\n",
    "            known_face_encodings.append(face_encoding)\n",
    "            known_face_names.append(name)\n",
    "\n",
    "    with open(f'{model_type}_known_faces.pickle', 'wb') as f:\n",
    "        pickle.dump((known_face_encodings, known_face_names), f)\n",
    "\n",
    "    # return known_face_encodings, known_face_names, ids\n",
    "model_type=\"face_recognition\"\n",
    "get_updated_embedding_and_name_list(name_list,link_list,model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of name list: 25\n",
      "Length of face embeddings: 25\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "model_type = \"facenet\"\n",
    "known=[]\n",
    "names=[]\n",
    "ids=[]\n",
    "with open(f'{model_type}_known_faces.pickle', 'rb') as f:\n",
    "    known, names = pickle.load(f)\n",
    "\n",
    "print(\"Length of name list:\", len(known))\n",
    "print(\"Length of face embeddings:\", len(names))\n",
    "for i in known:\n",
    "    print(type(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
